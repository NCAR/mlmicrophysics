{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 14:35:30.120801: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-21 14:35:30.153241: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 14:35:30.983894: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 14:35:30.984972: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 14:35:35.973573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import neural network, transformers, base input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the saved neural network\n",
    "nn_tau_em = load_model(\"/glade/work/wchuang/mlmicrophysics/tau_run_10/optimized/quantile_neural_net_keras.h5\")\n",
    "\n",
    "# Import the quantile transformers\n",
    "with open(\"/glade/work/wchuang/mlmicrophysics/tau_run_10/optimized/output_quantile_transform.pkl\", \"rb\") as out_quant_transform_file:\n",
    "    output_scaler = pickle.load(out_quant_transform_file)\n",
    "with open(\"/glade/work/wchuang/mlmicrophysics/tau_run_10/optimized/input_quantile_transform.pkl\", \"rb\") as in_quant_transform_file:\n",
    "    input_scaler = pickle.load(in_quant_transform_file)\n",
    "\n",
    "# Read in the fortran-scam inputs\n",
    "fortran_directory = \"/glade/derecho/scratch/wchuang/scam_ml_port6_emulate8_optimized.arm97/run/\"\n",
    "fortran_input_file = fortran_directory + \"test_input.dat\"\n",
    "input = np.fromfile(fortran_input_file, dtype=np.float64, sep=' ').reshape(1, -1)\n",
    "\n",
    "# Set column names for inputs and outputs\n",
    "input_col_names = [\"qc\", \"qr\", \"nc\", \"nr\", \"pgam\", \"lamc\", \"lamr\", \"n0r\", \"rho_clubb\"]\n",
    "output_col_names = [\"qctend\", \"nctend\", \"nrtend\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the various inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.src.losses.huber(y_true, y_pred, delta=1.0)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_tau_em.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qc</th>\n",
       "      <th>qr</th>\n",
       "      <th>nc</th>\n",
       "      <th>nr</th>\n",
       "      <th>pgam</th>\n",
       "      <th>lamc</th>\n",
       "      <th>lamr</th>\n",
       "      <th>n0r</th>\n",
       "      <th>rho_clubb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.333108e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.360965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>222222.22214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             qc   qr          nc   nr       pgam          lamc  lamr  n0r  \\\n",
       "0  1.333108e-08  0.0  158.360965  0.0  10.111111  222222.22214   0.0  0.0   \n",
       "\n",
       "   rho_clubb  \n",
       "0   0.989029  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(input, columns=input_col_names)\n",
    "input = input[:,:]\n",
    "pd.DataFrame(input, columns=input_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/wchuang/.local/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qc</th>\n",
       "      <th>qr</th>\n",
       "      <th>nc</th>\n",
       "      <th>nr</th>\n",
       "      <th>pgam</th>\n",
       "      <th>lamc</th>\n",
       "      <th>lamr</th>\n",
       "      <th>n0r</th>\n",
       "      <th>rho_clubb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911275</td>\n",
       "      <td>0.344813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qc   qr   nc   nr      pgam      lamc  lamr  n0r  rho_clubb\n",
       "0  0.0  0.0  0.0  0.0  0.911275  0.344813   0.0  0.0   0.408934"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_quantile = pd.DataFrame(input_scaler.transform(input), columns=input_col_names)\n",
    "input_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1553d12cfd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.68098989, 0.95264907, 0.94627122]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_quantile = nn_tau_em.predict(input_quantile)\n",
    "output_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/wchuang/.local/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qctend</th>\n",
       "      <th>nctend</th>\n",
       "      <th>nrtend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.878286e-09</td>\n",
       "      <td>-9.743312</td>\n",
       "      <td>37.28586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         qctend    nctend    nrtend\n",
       "0 -3.878286e-09 -9.743312  37.28586"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output_scaler.inverse_transform(output_quantile)\n",
    "pd.DataFrame(output, columns=output_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the input quantile scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.91127528 0.34481357\n",
      "  0.         0.         0.40893432]]\n",
      "[[0.         0.         0.         0.         0.91127549 0.34481345\n",
      "  0.         0.         0.40893432]]\n",
      "Arrays are equal within the specified tolerance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/wchuang/.local/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # Read in the fortran quantile inputs\n",
    "fortran_input_quantile_file = fortran_directory + \"test_quantile_input.dat\"\n",
    "fortran_input_quantile = np.fromfile(fortran_input_quantile_file, dtype=np.float64, sep=' ').reshape(1, -1)\n",
    "fortran_input_quantile\n",
    "print(fortran_input_quantile[:,:])\n",
    "# # Quantile transform with the python scaler\n",
    "input_quantile = input_scaler.transform(pd.DataFrame(input))\n",
    "print(input_quantile)\n",
    "# # Compare python-quantile-transformed inputs to the fortran-imported inputs\n",
    "input_quantile_same = np.allclose(fortran_input_quantile[:,:], input_quantile, atol=1e-7)\n",
    "input_quantile_same\n",
    "# # Are they the same?\n",
    "if input_quantile_same:\n",
    "    print(\"Arrays are equal within the specified tolerance.\")\n",
    "else:\n",
    "    print(\"Arrays are not equal within the specified tolerance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the neural network, which gives us the output quantile values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.68099008 0.95264908 0.9462712 ]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[0.68098987 0.95264907 0.94627123]]\n",
      "Arrays are equal within the specified tolerance.\n"
     ]
    }
   ],
   "source": [
    "fortran_output_quantile_file = fortran_directory + \"test_quantile_output.dat\"\n",
    "fortran_output_quantile = np.fromfile(fortran_output_quantile_file, dtype=np.float64, sep=' ').reshape(1, -1)\n",
    "print(fortran_output_quantile[:,:])\n",
    "# Run the quantile transformed inputs through the python nn to get python-quantile-transformed outputs\n",
    "output_quantile = nn_tau_em.predict(input_quantile)\n",
    "print(output_quantile)\n",
    "# Compare the python-quantile-transformed outputs to the fortran-imported-quantile-transformed outputs\n",
    "output_quantile_same = np.allclose(output_quantile, fortran_output_quantile[:,:], atol=1e-7)\n",
    "# Are these the same?\n",
    "if output_quantile_same:\n",
    "    print(\"Arrays are equal within the specified tolerance.\")\n",
    "else:\n",
    "    print(\"Arrays are not equal within the specified tolerance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the output quantile scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.87827876e-09 -9.74331043e+00  3.72858520e+01]]\n",
      "[[-3.87828669e-09 -9.74331192e+00  3.72858607e+01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/wchuang/.local/lib/python3.9/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse quantile transform the outputs using python\n",
    "fortran_output_file = fortran_directory + \"test_output.dat\"\n",
    "fortran_output = np.fromfile(fortran_output_file, dtype=np.float64, sep=' ').reshape(1, -1)\n",
    "print(fortran_output[:,:])\n",
    "# Compare the python outputs to the fortran-imported outputs\n",
    "output = output_scaler.inverse_transform(output_quantile)\n",
    "print(output)\n",
    "# Are they the same?\n",
    "output_same = np.allclose(output, fortran_output[:,:], atol=1e-7)\n",
    "output_same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If all checks pass here then the fortran neural network has been implemented successfully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmicro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
