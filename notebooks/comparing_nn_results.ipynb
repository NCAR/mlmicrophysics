{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import yaml\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"/glade/p/cisl/aiml/ggantos/200607/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = sorted([x[0] for x in os.walk(models_dir)][1:])\n",
    "models = list(range(0,54))\n",
    "models.remove(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_scores = pd.read_csv(join(models_dir, \"cam_run5_models_0/dnn_classifier_scores.csv\"))\n",
    "regressor_scores = pd.read_csv(join(models_dir, \"cam_run5_models_0/dnn_regressor_scores.csv\"))\n",
    "classifier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_weight = [1.0e-3, 1.0e-4, 1.0e-5]\n",
    "lrs = [0.001, 0.0001, 0.00001]\n",
    "hidden_layers = [2, 3, 4]\n",
    "activation = ['relu', 'tanh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_reg = ['qrtend_TAU_1', 'nctend_TAU_1', 'nrtend_TAU_-1', 'nrtend_TAU_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs_dict = {}\n",
    "for i in models:\n",
    "    y = yaml.load(open(f'../config/200607/cesm_tau_run5_full_train_nn_{i}.yml'), Loader=yaml.FullLoader)\n",
    "    regs_dict[i] = {}\n",
    "    regs_dict[i]['activation'] = y['classifier_networks']['activation']\n",
    "    regs_dict[i]['hidden_layers'] = y['classifier_networks']['hidden_layers']\n",
    "    regs_dict[i]['lr'] = y['classifier_networks']['lr']\n",
    "    regs_dict[i]['l2_weight'] = y['classifier_networks']['l2_weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressions = {}\n",
    "for out in outputs_reg:\n",
    "    regressions[out] = {}\n",
    "    ids = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    r2 = []\n",
    "    hellinger = []\n",
    "    for i in models:\n",
    "        reg = pd.read_csv(join(models_dir, f\"cam_run5_models_{i}/dnn_regressor_scores.csv\"))\n",
    "        ids.append(i)\n",
    "        rmse.append(float(reg.loc[reg['Output'] == out][\"rmse\"]))\n",
    "        mae.append(float(reg.loc[reg['Output'] == out][\"mae\"]))\n",
    "        r2.append(float(reg.loc[reg['Output'] == out][\"r2\"]))\n",
    "        hellinger.append(float(reg.loc[reg['Output'] == out][\"hellinger\"]))\n",
    "    regressions[out][\"ids\"] = ids\n",
    "    regressions[out][\"rmse\"] = rmse\n",
    "    regressions[out][\"mae\"] = mae\n",
    "    regressions[out][\"r2\"] = r2\n",
    "    regressions[out][\"hellinger\"] = hellinger\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, figsize=(16,8))\n",
    "for out, ax in zip(outputs_reg, (ax1, ax2, ax3, ax4)):\n",
    "    ax.plot(regressions[out][\"rmse\"], label=\"rmse\")\n",
    "    top = sorted(range(len(regressions[out][\"rmse\"])), key = lambda sub: regressions[out][\"rmse\"][sub])[-N:] \n",
    "    tops.append(top)\n",
    "    for i in top:\n",
    "        ax.annotate(i, (i, regressions[out][\"rmse\"][i]))\n",
    "    ax.plot(regressions[out][\"mae\"], label=\"mae\")\n",
    "    ax.plot(regressions[out][\"r2\"], label=\"r2\")\n",
    "    top = sorted(range(len(regressions[out][\"r2\"])), key = lambda sub: regressions[out][\"r2\"][sub])[-N:] \n",
    "    tops.append(top)\n",
    "    for i in top:\n",
    "        ax.annotate(i, (i, regressions[out][\"r2\"][i]))\n",
    "    ax.plot(regressions[out][\"hellinger\"], label=\"hellinger\")\n",
    "    plt.subplots_adjust(wspace=None, hspace=None)\n",
    "plt.subplots_adjust(wspace = 0)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_class = ['qrtend_TAU', 'nctend_TAU', 'nrtend_TAU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = {}\n",
    "for out in outputs_class:\n",
    "    classifications[out] = {}\n",
    "    ids = []\n",
    "    accuracy = []\n",
    "    heidke = []\n",
    "    peirce = []\n",
    "    for i in models:\n",
    "        clss = pd.read_csv(join(models_dir, f\"cam_run5_models_{i}/dnn_classifier_scores.csv\"))\n",
    "        ids.append(i)\n",
    "        accuracy.append(float(clss.loc[clss['Output'] == out][\"accuracy\"]))\n",
    "        heidke.append(float(clss.loc[clss['Output'] == out][\"heidke\"]))\n",
    "        peirce.append(float(clss.loc[clss['Output'] == out][\"peirce\"]))\n",
    "    classifications[out][\"ids\"] = ids\n",
    "    classifications[out][\"accuracy\"] = accuracy\n",
    "    classifications[out][\"heidke\"] = heidke\n",
    "    classifications[out][\"peirce\"] = peirce\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(15,8))\n",
    "for out, ax in zip(outputs_class, (ax1, ax2, ax3)):\n",
    "    ax.plot(classifications[out][\"accuracy\"], label=\"accuracy\")\n",
    "    top = sorted(range(len(classifications[out][\"accuracy\"])), key = lambda sub: classifications[out][\"accuracy\"][sub])[-N:]\n",
    "    tops.append(top)\n",
    "    for i in top:\n",
    "        ax.annotate(i, (i, classifications[out][\"accuracy\"][i]))\n",
    "    ax.plot(classifications[out][\"heidke\"], label=\"heidke\")\n",
    "    ax.plot(classifications[out][\"peirce\"], label=\"peirce\")\n",
    "    ax.set_title(out)\n",
    "plt.subplots_adjust(wspace = 0)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = np.array(tops)\n",
    "print(tops.shape)\n",
    "tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_intersection = set(tops[0]).intersection(*tops)\n",
    "tops_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(tops, return_counts=True)\n",
    "for e, c in zip (unique_elements, counts_elements):\n",
    "    print (f\"Element {e} has a frequency count of {c}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_top = [11,14,17,20,23,26,49,52]\n",
    "for i in tops_top:\n",
    "    print (regs_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
